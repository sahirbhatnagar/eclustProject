{
    "docs": [
        {
            "location": "/", 
            "text": "Eclust: A Statistical Software Tool for the Analysis of High-Dimensional Interactions\n\n\nThis software is written in the open source software environment \nR\n. It's main functionality is to fit statistical models for analyzing interactions between a high dimensional dataset (e.g. genomics, brain imaging), the environment and a response.\n\n\nThe software is still in development mode.\n\n\nInstallation\n\n\nThe software package is available on \nGithub\n and can be installed directly from within R using the following commands (note: you will need the \ndevtools\n package prior to installing the \neclust\n package)\n\n\nlibrary(devtools)\ninstall_github('sahirbhatnagar/eclust')", 
            "title": "Home"
        }, 
        {
            "location": "/#eclust-a-statistical-software-tool-for-the-analysis-of-high-dimensional-interactions", 
            "text": "This software is written in the open source software environment  R . It's main functionality is to fit statistical models for analyzing interactions between a high dimensional dataset (e.g. genomics, brain imaging), the environment and a response.  The software is still in development mode.", 
            "title": "Eclust: A Statistical Software Tool for the Analysis of High-Dimensional Interactions"
        }, 
        {
            "location": "/#installation", 
            "text": "The software package is available on  Github  and can be installed directly from within R using the following commands (note: you will need the  devtools  package prior to installing the  eclust  package)  library(devtools)\ninstall_github('sahirbhatnagar/eclust')", 
            "title": "Installation"
        }, 
        {
            "location": "/vignette/", 
            "text": "Eclust Vignette\n\n\nSahir R. Bhatnagar\n\n\nr Sys.Date()\n  \n\n\nLoad Required Packages\n\n\nlibrary(knitr)\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(latex2exp)\nlibrary(dplyr)\nlibrary(plyr)\nlibrary(glmnet)\nlibrary(stringr)\nlibrary(DT)\n\n\n\n\nSimulate Data\n\n\nset.seed(123456)\n\n# number of predictors\np = 10 \n\n# number of test subjects\nn = 200\n\n# correlation between X's\nrho = 0.50\n\n# signal to noise ratio\nsignal_to_noise_ratio = 4\n\n# names of the main effects, this will be used in many of the functions\nmain_effect_names \n- paste0(\nx\n,1:p) \n\n# names of the active set\ntrue_var_names \n- c(\nx1\n,\nx2\n,\nx3\n,\nx4\n,\nx1:x2\n, \nx1:x3\n, \nx1:x4\n, \nx2:x3\n, \nx2:x4\n, \nx3:x4\n)\n\n# different true coefficient vectors as in Table 1 of Choi et al. \nbeta1 \n- c(7,2,1,1,0,0,0,0,0,0) %\n% magrittr::set_names(true_var_names)\nbeta2 \n- c(7,2,1,1,1,0,0,0.5,0.4,0.1) %\n% magrittr::set_names(true_var_names)\nbeta3 \n- c(7,2,1,1,7,7,7,2,2,1) %\n% magrittr::set_names(true_var_names)\nbeta4 \n- c(7,2,1,1,14,14,14,4,4,2) %\n% magrittr::set_names(true_var_names)\nbeta5 \n- c(0,0,0,0,7,7,7,2,2,1) %\n% magrittr::set_names(true_var_names)\n\n# simulate Toeplitz like correlation structure between X's\nH \n- abs(outer(1:p, 1:p, \n-\n))\ncor \n- rho^H\n\n# generate X's from multivariate normal and label the matrix\nDT \n- MASS::mvrnorm(n = n, mu = rep(0,p), Sigma = cor) %\n% \n    magrittr::set_colnames(paste0(\nx\n,1:p)) %\n% \n    set_rownames(paste0(\nSubject\n,1:n))\n\n# create X matrix which contains all main effects and interactions\n# but not the intercept\nX \n- model.matrix(\n    as.formula(paste0(\n~(\n,paste0(main_effect_names, collapse = \n+\n),\n)^2-1\n)), \n    data = DT %\n% as.data.frame()) \n\n# generate response with user defined signal to noise ratio \ny.star \n- X[,names(beta4)] %*% beta4\nerror \n- rnorm(n)\nk \n- sqrt(var(y.star)/(signal_to_noise_ratio*var(error))) \nY \n- y.star + k*error \ncolnames(Y) \n- \nY\n\n\n# names of interaction variables assuming interaction terms contain a \n:\n\n# this will be used in many of the functions\n# names must appear in the same order as X matrix\ninteraction_names \n- grep(\n:\n, colnames(X), value = T)\nmain_effect_names \n- setdiff(colnames(X), interaction_names)\n\n\n\n\nAnalysis\n\n\nRunning the Strong heredity interaction model once using the \nshim\n function\n\n\n# load eclust library\nlibrary(eclust)\n\nres \n- shim(x = X, y = Y,\n            main.effect.names = main_effect_names,\n            interaction.names = interaction_names,\n            lambda.beta = NULL,\n            lambda.gamma = NULL, \n            nlambda.gamma = 12, \n            nlambda.beta = 10,\n            nlambda = 120, \n            threshold = 1e-04, \n            max.iter = 200,\n            initialization.type = \nridge\n, \n            intercept = TRUE,\n            normalize = TRUE, \n            verbose = TRUE, \n            cores = 2)\n\n\n\n\nnames(res)\n\n\n\n\n##  [1] \nb0\n                \nbeta\n              \nalpha\n            \n##  [4] \ngamma\n             \nlambda.beta\n       \nlambda.gamma\n     \n##  [7] \ntuning.parameters\n \ndfbeta\n            \ndfalpha\n          \n## [10] \nconverged\n         \nx\n                 \ny\n                \n## [13] \nbx\n                \nby\n                \nsx\n               \n## [16] \nintercept\n         \nnormalize\n         \ncall\n             \n## [19] \nnlambda.gamma\n     \nnlambda.beta\n      \nnlambda\n          \n## [22] \ninteraction.names\n \nmain.effect.names\n\n\n\n\n\nMain effect ($\\beta$) parameter estimates\n\n\nInteraction effect ($\\alpha$) parameter estimates\n\n\nSequence of Tuning Parameters\n\n\nCross Validation using the \ncv.shim\n function\n\n\nlibrary(doMC)\nregisterDoMC(cores = 10)\ncv.res \n- cv.shim(x = X, y = Y,\n            main.effect.names = main_effect_names,\n            interaction.names = interaction_names,\n            lambda.beta = NULL,\n            lambda.gamma = NULL, \n            nlambda.gamma = 12, \n            nlambda.beta = 10,\n            nlambda = 120, \n            threshold = 1e-04, \n            max.iter = 200,\n            initialization.type = \nridge\n, \n            intercept = TRUE,\n            normalize = TRUE, \n            verbose = FALSE, \n            parallel = TRUE,\n            type.measure = c(\nmse\n), \n            nfolds = 10)\n\nnames(cv.res)\n\n\n\n\n##  [1] \nlambda.beta\n     \nlambda.gamma\n    \ncvm\n            \n##  [4] \ncvsd\n            \ncvup\n            \ncvlo\n           \n##  [7] \nnz.main\n         \nname\n            \nnz.interaction\n \n## [10] \nshim.fit\n        \nconverged\n       \ncvm.mat.all\n    \n## [13] \ndf\n              \nlambda.min.beta\n \nlambda.min.name\n\n## [16] \nlambda.1se.beta\n \nlambda.1se.name\n\n\n\n\n\nCross Validation Plot\n\n\nplot(cv.res)\n\n\n\n\n\n\nCoefficient Estimates\n\n\ncoef(cv.res, s = \nlambda.1se\n)\n\n\n\n\n## 56 x 1 sparse Matrix of class \ndgCMatrix\n\n##              Y\n## X                    s44\n##   (Intercept)  4.4706024\n##   x1          12.6502968\n##   x2           7.6899616\n##   x3          10.2182909\n##   x4           .        \n##   x5           .        \n##   x6           .        \n##   x7           3.9026677\n##   x8           .        \n##   x9           .        \n##   x10          .        \n##   x1:x2        9.2706249\n##   x1:x3       18.3317082\n##   x1:x4        .        \n##   x1:x5        .        \n##   x1:x6        .        \n##   x1:x7        0.7652197\n##   x1:x8        .        \n##   x1:x9        .        \n##   x1:x10       .        \n##   x2:x3        6.4082682\n##   x2:x4        .        \n##   x2:x5        .        \n##   x2:x6        .        \n##   x2:x7        .        \n##   x2:x8        .        \n##   x2:x9        .        \n##   x2:x10       .        \n##   x3:x4        .        \n##   x3:x5        .        \n##   x3:x6        .        \n##   x3:x7       -2.6885265\n##   x3:x8        .        \n##   x3:x9        .        \n##   x3:x10       .        \n##   x4:x5        .        \n##   x4:x6        .        \n##   x4:x7        .        \n##   x4:x8        .        \n##   x4:x9        .        \n##   x4:x10       .        \n##   x5:x6        .        \n##   x5:x7        .        \n##   x5:x8        .        \n##   x5:x9        .        \n##   x5:x10       .        \n##   x6:x7        .        \n##   x6:x8        .        \n##   x6:x9        .        \n##   x6:x10       .        \n##   x7:x8        .        \n##   x7:x9        .        \n##   x7:x10       .        \n##   x8:x9        .        \n##   x8:x10       .        \n##   x9:x10       .\n\n\n\n\ncoef(cv.res, s = \nlambda.min\n)\n\n\n\n\n## 56 x 1 sparse Matrix of class \ndgCMatrix\n\n##              Y\n## X                   s87\n##   (Intercept)  5.190222\n##   x1          13.212962\n##   x2           8.337120\n##   x3           8.926785\n##   x4           .       \n##   x5           .       \n##   x6           .       \n##   x7           .       \n##   x8           .       \n##   x9           .       \n##   x10          1.871489\n##   x1:x2        9.223568\n##   x1:x3       18.409148\n##   x1:x4        .       \n##   x1:x5        .       \n##   x1:x6        .       \n##   x1:x7        .       \n##   x1:x8        .       \n##   x1:x9        .       \n##   x1:x10       5.373335\n##   x2:x3        5.856195\n##   x2:x4        .       \n##   x2:x5        .       \n##   x2:x6        .       \n##   x2:x7        .       \n##   x2:x8        .       \n##   x2:x9        .       \n##   x2:x10      -6.956081\n##   x3:x4        .       \n##   x3:x5        .       \n##   x3:x6        .       \n##   x3:x7        .       \n##   x3:x8        .       \n##   x3:x9        .       \n##   x3:x10       3.012622\n##   x4:x5        .       \n##   x4:x6        .       \n##   x4:x7        .       \n##   x4:x8        .       \n##   x4:x9        .       \n##   x4:x10       .       \n##   x5:x6        .       \n##   x5:x7        .       \n##   x5:x8        .       \n##   x5:x9        .       \n##   x5:x10       .       \n##   x6:x7        .       \n##   x6:x8        .       \n##   x6:x9        .       \n##   x6:x10       .       \n##   x7:x8        .       \n##   x7:x9        .       \n##   x7:x10       .       \n##   x8:x9        .       \n##   x8:x10       .       \n##   x9:x10       .", 
            "title": "Vignette"
        }, 
        {
            "location": "/vignette/#eclust-vignette", 
            "text": "Sahir R. Bhatnagar  r Sys.Date()", 
            "title": "Eclust Vignette"
        }, 
        {
            "location": "/vignette/#load-required-packages", 
            "text": "library(knitr)\nlibrary(data.table)\nlibrary(magrittr)\nlibrary(ggplot2)\nlibrary(latex2exp)\nlibrary(dplyr)\nlibrary(plyr)\nlibrary(glmnet)\nlibrary(stringr)\nlibrary(DT)", 
            "title": "Load Required Packages"
        }, 
        {
            "location": "/vignette/#simulate-data", 
            "text": "set.seed(123456)\n\n# number of predictors\np = 10 \n\n# number of test subjects\nn = 200\n\n# correlation between X's\nrho = 0.50\n\n# signal to noise ratio\nsignal_to_noise_ratio = 4\n\n# names of the main effects, this will be used in many of the functions\nmain_effect_names  - paste0( x ,1:p) \n\n# names of the active set\ntrue_var_names  - c( x1 , x2 , x3 , x4 , x1:x2 ,  x1:x3 ,  x1:x4 ,  x2:x3 ,  x2:x4 ,  x3:x4 )\n\n# different true coefficient vectors as in Table 1 of Choi et al. \nbeta1  - c(7,2,1,1,0,0,0,0,0,0) % % magrittr::set_names(true_var_names)\nbeta2  - c(7,2,1,1,1,0,0,0.5,0.4,0.1) % % magrittr::set_names(true_var_names)\nbeta3  - c(7,2,1,1,7,7,7,2,2,1) % % magrittr::set_names(true_var_names)\nbeta4  - c(7,2,1,1,14,14,14,4,4,2) % % magrittr::set_names(true_var_names)\nbeta5  - c(0,0,0,0,7,7,7,2,2,1) % % magrittr::set_names(true_var_names)\n\n# simulate Toeplitz like correlation structure between X's\nH  - abs(outer(1:p, 1:p,  - ))\ncor  - rho^H\n\n# generate X's from multivariate normal and label the matrix\nDT  - MASS::mvrnorm(n = n, mu = rep(0,p), Sigma = cor) % % \n    magrittr::set_colnames(paste0( x ,1:p)) % % \n    set_rownames(paste0( Subject ,1:n))\n\n# create X matrix which contains all main effects and interactions\n# but not the intercept\nX  - model.matrix(\n    as.formula(paste0( ~( ,paste0(main_effect_names, collapse =  + ), )^2-1 )), \n    data = DT % % as.data.frame()) \n\n# generate response with user defined signal to noise ratio \ny.star  - X[,names(beta4)] %*% beta4\nerror  - rnorm(n)\nk  - sqrt(var(y.star)/(signal_to_noise_ratio*var(error))) \nY  - y.star + k*error \ncolnames(Y)  -  Y \n\n# names of interaction variables assuming interaction terms contain a  : \n# this will be used in many of the functions\n# names must appear in the same order as X matrix\ninteraction_names  - grep( : , colnames(X), value = T)\nmain_effect_names  - setdiff(colnames(X), interaction_names)", 
            "title": "Simulate Data"
        }, 
        {
            "location": "/vignette/#analysis", 
            "text": "", 
            "title": "Analysis"
        }, 
        {
            "location": "/vignette/#running-the-strong-heredity-interaction-model-once-using-the-shim-function", 
            "text": "# load eclust library\nlibrary(eclust)\n\nres  - shim(x = X, y = Y,\n            main.effect.names = main_effect_names,\n            interaction.names = interaction_names,\n            lambda.beta = NULL,\n            lambda.gamma = NULL, \n            nlambda.gamma = 12, \n            nlambda.beta = 10,\n            nlambda = 120, \n            threshold = 1e-04, \n            max.iter = 200,\n            initialization.type =  ridge , \n            intercept = TRUE,\n            normalize = TRUE, \n            verbose = TRUE, \n            cores = 2)  names(res)  ##  [1]  b0                  beta                alpha             \n##  [4]  gamma               lambda.beta         lambda.gamma      \n##  [7]  tuning.parameters   dfbeta              dfalpha           \n## [10]  converged           x                   y                 \n## [13]  bx                  by                  sx                \n## [16]  intercept           normalize           call              \n## [19]  nlambda.gamma       nlambda.beta        nlambda           \n## [22]  interaction.names   main.effect.names", 
            "title": "Running the Strong heredity interaction model once using the shim function"
        }, 
        {
            "location": "/vignette/#main-effect-beta-parameter-estimates", 
            "text": "", 
            "title": "Main effect ($\\beta$) parameter estimates"
        }, 
        {
            "location": "/vignette/#interaction-effect-alpha-parameter-estimates", 
            "text": "", 
            "title": "Interaction effect ($\\alpha$) parameter estimates"
        }, 
        {
            "location": "/vignette/#sequence-of-tuning-parameters", 
            "text": "", 
            "title": "Sequence of Tuning Parameters"
        }, 
        {
            "location": "/vignette/#cross-validation-using-the-cvshim-function", 
            "text": "library(doMC)\nregisterDoMC(cores = 10)\ncv.res  - cv.shim(x = X, y = Y,\n            main.effect.names = main_effect_names,\n            interaction.names = interaction_names,\n            lambda.beta = NULL,\n            lambda.gamma = NULL, \n            nlambda.gamma = 12, \n            nlambda.beta = 10,\n            nlambda = 120, \n            threshold = 1e-04, \n            max.iter = 200,\n            initialization.type =  ridge , \n            intercept = TRUE,\n            normalize = TRUE, \n            verbose = FALSE, \n            parallel = TRUE,\n            type.measure = c( mse ), \n            nfolds = 10)\n\nnames(cv.res)  ##  [1]  lambda.beta       lambda.gamma      cvm             \n##  [4]  cvsd              cvup              cvlo            \n##  [7]  nz.main           name              nz.interaction  \n## [10]  shim.fit          converged         cvm.mat.all     \n## [13]  df                lambda.min.beta   lambda.min.name \n## [16]  lambda.1se.beta   lambda.1se.name", 
            "title": "Cross Validation using the cv.shim function"
        }, 
        {
            "location": "/vignette/#cross-validation-plot", 
            "text": "plot(cv.res)", 
            "title": "Cross Validation Plot"
        }, 
        {
            "location": "/vignette/#coefficient-estimates", 
            "text": "coef(cv.res, s =  lambda.1se )  ## 56 x 1 sparse Matrix of class  dgCMatrix \n##              Y\n## X                    s44\n##   (Intercept)  4.4706024\n##   x1          12.6502968\n##   x2           7.6899616\n##   x3          10.2182909\n##   x4           .        \n##   x5           .        \n##   x6           .        \n##   x7           3.9026677\n##   x8           .        \n##   x9           .        \n##   x10          .        \n##   x1:x2        9.2706249\n##   x1:x3       18.3317082\n##   x1:x4        .        \n##   x1:x5        .        \n##   x1:x6        .        \n##   x1:x7        0.7652197\n##   x1:x8        .        \n##   x1:x9        .        \n##   x1:x10       .        \n##   x2:x3        6.4082682\n##   x2:x4        .        \n##   x2:x5        .        \n##   x2:x6        .        \n##   x2:x7        .        \n##   x2:x8        .        \n##   x2:x9        .        \n##   x2:x10       .        \n##   x3:x4        .        \n##   x3:x5        .        \n##   x3:x6        .        \n##   x3:x7       -2.6885265\n##   x3:x8        .        \n##   x3:x9        .        \n##   x3:x10       .        \n##   x4:x5        .        \n##   x4:x6        .        \n##   x4:x7        .        \n##   x4:x8        .        \n##   x4:x9        .        \n##   x4:x10       .        \n##   x5:x6        .        \n##   x5:x7        .        \n##   x5:x8        .        \n##   x5:x9        .        \n##   x5:x10       .        \n##   x6:x7        .        \n##   x6:x8        .        \n##   x6:x9        .        \n##   x6:x10       .        \n##   x7:x8        .        \n##   x7:x9        .        \n##   x7:x10       .        \n##   x8:x9        .        \n##   x8:x10       .        \n##   x9:x10       .  coef(cv.res, s =  lambda.min )  ## 56 x 1 sparse Matrix of class  dgCMatrix \n##              Y\n## X                   s87\n##   (Intercept)  5.190222\n##   x1          13.212962\n##   x2           8.337120\n##   x3           8.926785\n##   x4           .       \n##   x5           .       \n##   x6           .       \n##   x7           .       \n##   x8           .       \n##   x9           .       \n##   x10          1.871489\n##   x1:x2        9.223568\n##   x1:x3       18.409148\n##   x1:x4        .       \n##   x1:x5        .       \n##   x1:x6        .       \n##   x1:x7        .       \n##   x1:x8        .       \n##   x1:x9        .       \n##   x1:x10       5.373335\n##   x2:x3        5.856195\n##   x2:x4        .       \n##   x2:x5        .       \n##   x2:x6        .       \n##   x2:x7        .       \n##   x2:x8        .       \n##   x2:x9        .       \n##   x2:x10      -6.956081\n##   x3:x4        .       \n##   x3:x5        .       \n##   x3:x6        .       \n##   x3:x7        .       \n##   x3:x8        .       \n##   x3:x9        .       \n##   x3:x10       3.012622\n##   x4:x5        .       \n##   x4:x6        .       \n##   x4:x7        .       \n##   x4:x8        .       \n##   x4:x9        .       \n##   x4:x10       .       \n##   x5:x6        .       \n##   x5:x7        .       \n##   x5:x8        .       \n##   x5:x9        .       \n##   x5:x10       .       \n##   x6:x7        .       \n##   x6:x8        .       \n##   x6:x9        .       \n##   x6:x10       .       \n##   x7:x8        .       \n##   x7:x9        .       \n##   x7:x10       .       \n##   x8:x9        .       \n##   x8:x10       .       \n##   x9:x10       .", 
            "title": "Coefficient Estimates"
        }, 
        {
            "location": "/references/", 
            "text": "References\n\n\n\n\n\n\nChoi, Nam Hee, William Li, and Ji Zhu. \"Variable selection with the strong heredity constraint and its oracle property.\" Journal of the American Statistical Association 105.489 (2010): 354-364.\n\n\n\n\n\n\nChipman, Hugh. \"Bayesian variable selection with related predictors.\" Canadian Journal of Statistics 24.1 (1996): 17-36.", 
            "title": "References"
        }, 
        {
            "location": "/references/#references", 
            "text": "Choi, Nam Hee, William Li, and Ji Zhu. \"Variable selection with the strong heredity constraint and its oracle property.\" Journal of the American Statistical Association 105.489 (2010): 354-364.    Chipman, Hugh. \"Bayesian variable selection with related predictors.\" Canadian Journal of Statistics 24.1 (1996): 17-36.", 
            "title": "References"
        }
    ]
}